{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614ec218",
   "metadata": {},
   "source": [
    "# New York CitiBike Data Science Challenge\n",
    "\n",
    "Der Fahrradverleih CitiBike vermietet in New York über 12.000 Fahrräder an 750 \n",
    "Verleihstationen. Somit ist CitiBike eine echte Alternative zu den herkömmlichen \n",
    "Transportmitteln, wie z.B. U-bahn oder Taxi. \n",
    "\n",
    "Nehme an, es wäre das Jahr 2018. Mit einem gültigen 24 Stunden (3 Tage) Pass bzw. einer \n",
    "jährlichen Mitgliedschaft können Kunden ein Fahrrad an einer Verleihstation abholen und an \n",
    "einer beliebigen Station wieder abgeben. CitiBike stellt die durch den Verleih gesammelten \n",
    "Daten der Öffentlichkeit zur Verfügung. Deine Aufgabe als Data Scientist ist es, CitiBike dabei zu\n",
    "helfen diese Daten wertstiftend zu nutzen. \n",
    "\n",
    "In einem ersten Pilotprojekt sollst du hierfür die Daten analysieren und ein Modell bauen, mit \n",
    "welchem zwei Klassen von Nutzern identifiziert werden können; dies sind (i) customers (24 \n",
    "Stunden/ 3 Tage Pass) und (ii) subscribers (jährliche Mitgliedschaft).\n",
    "\n",
    "Eine Orientierungshilfe bei \n",
    "dieser Aufgabenstellung bieten dir die folgenen Arbeitsschritte:\n",
    " \n",
    "1. Lade diese Daten von Citibike für das Jahr 2018 herunter. Mach dich mit dem Inhalt des \n",
    "Datensatzes vertraut und bereite ihn für weitere Analysen auf. \n",
    "2. Visualisiere die Daten; sei kreativ und überlege dir geeignete Darstellungsformen für \n",
    "deine Entdeckungen. Nutze die Visualisierungen auch in deiner Ergebnispräsentation um \n",
    "deine Argumente zu unterstützen.\n",
    "3. Überlege dir geeignete Features (Merkmale) als Input für dein customer-subscriber-\n",
    "Modell. Konstruiere gegebenenfalls neue Features um dein Modell zu verbessern. \n",
    "4. Verteste verschiedene Modelle bzw. Methoden zur Klassifikation der Kundentypen \n",
    "subscribers und customers. Evaluiere die Performance der unterschiedlichen Modelle \n",
    "und begründe eine Modellauswahl.\n",
    "5. Skizziere mögliche Einsatzgebiete oder UseCases deiner Modelle\n",
    "6. Skizziere für CitiBike Kooperationsmöglichkeiten mit einer Versicherung (und/oder \n",
    "umgekehrt). \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba719c5a",
   "metadata": {},
   "source": [
    "## Imports und Co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generelles\n",
    "import os\n",
    "\n",
    "# Data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import shap\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hilfen\n",
    "from utils import crow_distance\n",
    "from utils import forward_feature_selection\n",
    "\n",
    "# Display\n",
    "pd.set_option('display.max_columns', 500)\n",
    "%matplotlib inline \n",
    "\n",
    "# Random seed\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Konstanten\n",
    "data_drop = 0.99\n",
    "max_trip_duration = 12 * 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23af23e",
   "metadata": {},
   "source": [
    "## Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a5937",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rohdaten einlesen, wir beschränken uns auf 1% der Daten um meine virtuelle Maschine zu schonen\n",
    "data_directory = 'data_NY/'\n",
    "files = sorted(os.listdir(data_directory))\n",
    "for index, file in enumerate(files):\n",
    "    if index == 0:\n",
    "        data = pd.read_csv(data_directory+file)\n",
    "        data.drop(np.random.choice(data.index, int(len(data)*data_drop), replace=False), inplace=True)\n",
    "    else:\n",
    "        data_tmp = pd.read_csv(data_directory+file)\n",
    "        data_tmp.drop(np.random.choice(data_tmp.index, int(len(data_tmp)*data_drop), replace=False), inplace=True)\n",
    "        data = pd.concat([data, data_tmp], ignore_index=True)\n",
    "\n",
    "# Datentyp verbessern\n",
    "for column in data.columns:\n",
    "    data.rename(columns={column: column.replace(' ', '_')}, inplace=True)\n",
    "data.starttime = pd.to_datetime(data.starttime)\n",
    "data.stoptime = pd.to_datetime(data.stoptime)\n",
    "\n",
    "# Rohdaten sichten\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6731cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks der Rohdaten\n",
    "\n",
    "print('Tripduration')\n",
    "print(f'Min: {np.min(data.tripduration)} s, Max: {np.max(data.tripduration)/3600:.0f} h\\n')\n",
    "\n",
    "print('Starttime')\n",
    "print(f'Min: {np.min(data.starttime)}, Max: {np.max(data.starttime)}\\n')\n",
    "\n",
    "print('Stoptime')\n",
    "print(f'Min: {np.min(data.stoptime)}, Max: {np.max(data.stoptime)}\\n')\n",
    "\n",
    "print('Start station id')\n",
    "print(f'Min: {np.min(data.start_station_id)}, Max: {np.max(data.start_station_id)}, #: {len(np.unique(data.start_station_id))}\\n')\n",
    "\n",
    "# print('Start station name')\n",
    "# print(f'#: {len(np.unique(data.start_station_name))}\\n')\n",
    "      \n",
    "print('Start station latitude')\n",
    "print(f'Min: {np.min(data.start_station_latitude)}, Max: {np.max(data.start_station_latitude)}, #: {len(np.unique(data.start_station_latitude))}\\n')\n",
    "\n",
    "print('Start station longtude')\n",
    "print(f'Min: {np.min(data.start_station_longitude)}, Max: {np.max(data.start_station_longitude)}, #: {len(np.unique(data.start_station_longitude))}\\n')\n",
    "\n",
    "print('End station id')\n",
    "print(f'Min: {np.min(data.end_station_id)}, Max: {np.max(data.end_station_id)}, #: {len(np.unique(data.end_station_id))}\\n')\n",
    "\n",
    "# print('End station name')\n",
    "# print(f'#: {len(np.unique(data.end_station_name))}\\n')\n",
    "\n",
    "print('End station latitude')\n",
    "print(f'Min: {np.min(data.end_station_latitude)}, Max: {np.max(data.end_station_latitude)}, #: {len(np.unique(data.end_station_latitude))}\\n')\n",
    "\n",
    "print('End station longitude')\n",
    "print(f'Min: {np.min(data.end_station_longitude)}, Max: {np.max(data.end_station_longitude)}, #: {len(np.unique(data.end_station_longitude))}\\n')\n",
    "\n",
    "print('Bikeid')\n",
    "print(f'Min: {np.min(data.bikeid)}, Max: {np.max(data.bikeid)}, #: {len(np.unique(data.bikeid))}\\n')\n",
    "\n",
    "print('Usertype')\n",
    "print(f'Types: {np.unique(data.usertype)}, #: {np.unique(data.usertype, return_counts=True)[1]}\\n')\n",
    "\n",
    "print('Birth year')\n",
    "print(f'Min: {np.min(data.birth_year)}, Max: {np.max(data.birth_year)}\\n')\n",
    "\n",
    "print('Gender')\n",
    "print(f'Types: {np.unique(data.gender)}, #: {np.unique(data.gender, return_counts=True)[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47660008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten säubern\n",
    "\n",
    "# Sortiere Fahrten aus, die länger als 2 Stunden dauerten\n",
    "len_before = len(data)\n",
    "data.drop(data[data.tripduration >= max_trip_duration].index, inplace=True)\n",
    "len_after = len(data)\n",
    "print(f'Dropped {len_before-len_after} lines due to excessive tripduration')\n",
    "\n",
    "# Macht es Sinn, Geburtsjahre vor 1918 auszusortieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88239517",
   "metadata": {},
   "source": [
    "### Erstes Fazit\n",
    "\n",
    "- Datensatz sehr groß, wir beschränken uns deswegen auf die Sommermonate\n",
    "- Datensatz ist 'imbalanced', 19 000 customer gegen 156 000 subscriber\n",
    "- Datenqualität ist okay, aber ein paar sehr alte Kunden, lange Fahrten und unhomogene Koordinatenangaben\n",
    "- Wir sollten schon vor der weiteren Analyse einen Teil der Daten beiseitelegen, um eine wirklich unabhängige Evaluation unseres Modells zu erreichen\n",
    "- Wir sollten schon bei der visuellen Analyse des Datensatzes die Aufgabenstellung im Auge behalten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd90f3",
   "metadata": {},
   "source": [
    "## Features für Customer-Subscriber-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918050d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start_hour_of_day']= [t.hour for t in data.starttime]\n",
    "\n",
    "data['start_day_of_week'] = [t.dayofweek for t in data.starttime]\n",
    "\n",
    "data['start_day_of_year'] = [t.dayofyear for t in data.starttime]\n",
    "\n",
    "data['duration_seconds'] = data.tripduration\n",
    "\n",
    "data['crow_distance_meters'] = crow_distance(data.start_station_latitude, data.start_station_longitude, data.end_station_latitude, data.end_station_longitude)\n",
    "\n",
    "data['crow_velocity_meters_per_second'] = data.crow_distance_meters / data.duration_seconds\n",
    "\n",
    "data['age'] = 2018 - data.birth_year\n",
    "\n",
    "data['gender_male'] = [1 if g==1 else 0 for g in data.gender]\n",
    "\n",
    "data['gender_female'] = [1 if g==2 else 0 for g in data.gender]\n",
    "\n",
    "data['gender_unknown'] = [1 if g==0 else 0 for g in data.gender]\n",
    "\n",
    "data['customer'] = [1 if u=='Customer' else 0 for u in data.usertype]\n",
    "\n",
    "data['subscriber'] = [1 if u=='Subscriber' else 0 for u in data.usertype]\n",
    "\n",
    "data['set'] = [np.random.choice(['train', 'dev', 'test'], p=[0.8, 0.1, 0.1]) for r in range(len(data))]\n",
    "\n",
    "data['train_set'] = [True if s=='train' else False for s in data.set]\n",
    "\n",
    "data['dev_set'] = [True if s=='dev' else False for s in data.set]\n",
    "\n",
    "data['test_set'] = [True if s=='test' else False for s in data.set]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eeff51",
   "metadata": {},
   "source": [
    "## Visualisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf200b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histogramme, sortiert nach customer und Subscriber\n",
    "plot_specs = [('start_hour_of_day', range(25)),\n",
    "              ('start_day_of_week', range(7)),\n",
    "              ('start_day_of_year', np.linspace(0, 366, num=20)),\n",
    "              ('duration_seconds', np.linspace(0, 3600, num=20)),\n",
    "              ('crow_distance_meters', np.linspace(0, 6000, num=20)),\n",
    "              ('crow_velocity_meters_per_second', np.linspace(0, 6, num=20)),\n",
    "              ('age', np.linspace(0, 80, num=20)),\n",
    "              ('gender_male', range(3)),\n",
    "              ('gender_female', range(3)),\n",
    "              ('gender_unknown', range(3))]\n",
    "\n",
    "data_customer = data[~data.test_set & data.customer==1]\n",
    "data_subscriber = data[~data.test_set & data.subscriber==1]\n",
    "\n",
    "for column, bins in plot_specs:\n",
    "    plt.hist([data_customer[column], data_subscriber[column]], bins, stacked=True, rwidth=.95, color=['tomato', 'silver'])\n",
    "    plt.title(f'{column} histogram')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c293b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wegstrecken, ebenfalls nach customer und subscriber \n",
    "\n",
    "for idx, row in data_customer.iterrows():\n",
    "    plt.plot([row.start_station_longitude, row.end_station_longitude], [row.start_station_latitude, row.end_station_latitude], alpha=0.01, color='tomato')\n",
    "plt.title('customer frequent routes')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "data_subscriber_for_plot = data_subscriber.drop(np.random.choice(data_subscriber.index, int(len(data_subscriber)*0.9), replace=False))\n",
    "for idx, row in data_subscriber.iterrows():\n",
    "    plt.plot([row.start_station_longitude, row.end_station_longitude], [row.start_station_latitude, row.end_station_latitude], alpha=0.01, color='silver')\n",
    "plt.title('subscriber frequent routes')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fec02",
   "metadata": {},
   "source": [
    "## Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs definieren\n",
    "feature_columns = ['start_hour_of_day',\n",
    "                   'start_day_of_week',\n",
    "                   'start_day_of_year',\n",
    "                   'duration_seconds',\n",
    "                   'crow_distance_meters',\n",
    "                   'crow_velocity_meters_per_second',\n",
    "                   'age',\n",
    "                   'gender_male',\n",
    "                   'gender_female',\n",
    "                   'gender_unknown']\n",
    "\n",
    "target_column = ['customer']\n",
    "\n",
    "# Training und validation data\n",
    "x_train = data.loc[data.train_set, feature_columns]\n",
    "x_dev = data.loc[data.dev_set, feature_columns]\n",
    "y_train = data.loc[data.train_set, target_column]\n",
    "y_dev = data.loc[data.dev_set, target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstes simples Modell: klassifiziere immer als Subscriber\n",
    "def S(x):\n",
    "    return [0] * len(x)\n",
    "\n",
    "y_dev_hat = simple_model(x_dev)\n",
    "\n",
    "# Confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_dev, y_dev_hat)\n",
    "plt.title('confusion matrix for linear classifier')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3226d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineare Klassifikation\n",
    "linear_model = SGDClassifier(max_iter=1000, tol=1e-13)\n",
    "linear_model.fit(x_train, y_train)\n",
    "y_dev_hat = linear_model.predict(x_dev)\n",
    "\n",
    "# Confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_dev, y_dev_hat)\n",
    "plt.title('confusion matrix for linear classifier')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5974d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest für Klassifikation\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(features_train, )\n",
    "y_dev_hat = RF.predict(x_dev)\n",
    "\n",
    "# Confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_dev, y_dev_hat)\n",
    "plt.title('confusion matrix for linear classifier')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea281993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Modell erklären\n",
    "explainer = shap.TreeExplainer(random_forest, x_dev)\n",
    "shap_values = explainer(x_dev)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche features sind sinnvoll?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa0b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64d4619",
   "metadata": {},
   "source": [
    "## Use cases für Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad56b17",
   "metadata": {},
   "source": [
    "- Fahrräder bereitstellen\n",
    "- Kunden elastizität, vielleicht Pauschale erhöhen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198b295",
   "metadata": {},
   "source": [
    "##  Kooperation mit Versicherung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8134857",
   "metadata": {},
   "source": [
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb8622",
   "metadata": {},
   "source": [
    "## Was ich noch gemacht hätte, wenn ich Zeit gehabt hätte\n",
    "\n",
    "- Datensatz als Graph betrachten, zwischen welchen Stationen fahren Customer und Subscriber gerne?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cfee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
